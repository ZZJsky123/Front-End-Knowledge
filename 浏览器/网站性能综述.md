### 前言

Steve Souders：

```
Web 开发，那你技术体系的根基就是 Web 和它赖以存在的大量网络协议：TCP、TLS、UDP、HTTP，
等等。这些协议分别有各自的性能特点和优化技巧，为开发高性能应用，你必须理
解为什么网络那么运行。
```

Ilya Grigorik

```
大多数网站性能的瓶颈都是延迟，而不是带宽！

延迟： 分组从信息源发送到目的地所需的时间
   传播延迟：消息从发送端到接收端需要的时间，是信号传播距离和速度的函数。
   传输延迟：把消息中的所有比特转移到链路中需要的时间，是消息长度和链路速率的函数。
   处理延迟：处理分组首部、检查位错误及确定分组目标所需的时间。
   排队延迟：到来的分组排队等待处理的时间。
   
带宽： 逻辑或物理通信路径最大的吞吐量

Ookla 运营的 http://speedtest.net 可以测试客户端到某个 [本地服务器] 的上传和下载速度
```

### TCP

```
1. TCP 报文格式
   a. 源端口号 16位  目的端口号 16 位
   b. 序列号 32 位
   c. 确认应答号： 32 位
   d. 首部长度 4 位  保留标志位：ACK/RST/SYN/FIN(重要的4个) 窗口大小16位
   e. 校验和 16 位 紧急指针 16 位
   f. 选项
   g. 数据
   
  序列号： 建立 TCP连接时， 生成初始的序列号，之后每次发送都会对序列号的数据进行增加
          其作用是用于解决帧的乱序问题。
  确认应答号： 用于指出已经接收到的帧数据， 表明该序号之前的数据都被接收到了 
  
  ACK: 该位为 1 时， 确认应答位必须有效， 除了 SYN 包之外(发起连接)， 其余包都为1
  RST： 该位为 1 时， TCP 发生异常， 此时必须断开 TCP 连接
  SYN:  该位为 1 时， 请求连接， 此时进行序列号初始值设定
  FIN： 该位为 1 时， 后面已经无数据， 希望断开连接。
  
2. 为什么需要 TCP 连接 ？ TCP 工作在哪一层
   TCP 工作在传输层， 其下的网络层 IP协议 不保证数据可靠交付，其只负责将 TCP 层数据包装成
   数据报进行转发， 但不保证是否转发成功， 是否按序转发, 也不保证数据包的完整性。
   因此 TCP 协议需要承担数据的可靠性， 他保证数据 [无损坏]， [无间隔]， [非冗余]， [按序]。
   
3. TCP 通信协议的特点：
     a. 面向连接： 进行 TCP 通信时需要端到端进行 一对一连接
     b. 可靠： 保证数据传输时的无损坏， 按序， 不冗余
     c. 面向字节流： 数据以字节流的形式
     
4. 如何唯一确定一个 TCP ：
        源端口号、 目的端口号 、源 IP 地址、 目的 IP 地址
        
5. 服务器上 TCP 最大可以连接的数量：
        a. 服务器上 目的IP地址 目的端口号不变， 理论上最大连接数量是 客户端的 IP地址个数 * 端口号数
                  IPV4   2^32 * 2^16 = 2^48
        b. TCP 数量未抵达理论数值的原因
                  a. 每个 socket 都是文件， 有文件描述符限制， 需要修改 ulimit 的数量
                  b. 内存限制
                  
6. TCP 和 UDP 的区别
        a.  连接： TCP 是面向连接的且是一对一， UDP 即刻发送可以一对一， 一对多， 多对多
        b.  可靠： TCP 是可靠传输保证数据成功抵达，并且按照顺序， 同时保证抵达数据无损， 
                  UDP 尽最大努力交付， 只负责发送，不保证数据的可靠性。
        c.  首部字段： TCP 的首部字段较多包括： 源端口号，目的端口号，序列号，确认应答号
                     保留位，窗口大小， 校验和，紧急指针。 UDP 只包含源端口号和目的端口
                     号， 包长度， 校验和 共计8个字节。
        d. 传输方式： TCP 是按流传输， 没有边界，但保证数据按照顺序
                    UDP 是一个包一个包传输， 数据之间边界明显， 并且会有乱序的可能
        e. 数据分片： TCP 数据长度大于 MSS 大小，会被分片， 传输过程中若分片丢失
                    只需要重新传入那个片。在传输层分片，在传输层组装。 mss 默认是
                    536 字节。
                    
                    UDP 在 IP 层进行分片， 若数据长度大于 MTU， 进行数据分片
                    不建议 UDP 数据长度大于 MTU， 一旦分片丢失按照可靠性要求需要
                    重新传输整个包而不是分片， 不符合 UDP 最大努力交付。在 IP 层
                    重新组装。 MTU 大小： 1472 字节上下 1500 字节 1K左右
                    
                     
7. TCP 应用：
              a. FTP 文件传输
              b. HTTP / HTTPS
              
8. TCP 为什么有首部长度字段， UDP 没有：
        1. UDP 首部长度固定， 而 TCP 首部长度有可变长的 [选项] 字段
        
9. TCP 为什么没有包长度， UDP 有
        1. TCP 数据长度等于 IP数据长度- IP首部长度 -TCP首部长度
        2. UDP 也可以根据这种方式算出来， 但是可能为了满足长度是 4字节的整数倍。

10. TCP 选项字段主要用于记录一些在通信过程中会经常使用到的值
        e.g:  MSS 大小  新的窗口大小等

11. TCP 建立连接： 
     1.  建立连接之前， 客户端和服务器端都处于 closed 状态
     2.  开始建立， 服务器端首先发生变化， 首先监听某个端口并处于监听状态。
     3.  客户端初始化序列值， 生成 client_isn ,并将其放入序号字段中， 并将
         SYN 标志位：1， 发送给服务器， 此时状态变为 SYN_SEND。
     4.  服务器收到后， 初始化随机序列号server_isn， 并将其填入序列字段， 并将客户端的发送的TCP
         数据中 client_isn + 1 填入到确认序列号中，将 ACK 和 SYN 标志位设置成 1
         返回给客户端。服务器端状态更改为： [SYN_RCVD]
     5. 客户端收到报文后， 需要返回应答报文， 将服务器端的 server_isn + 1填入确认应答字段
        并将 ACK :1, 此时可以携带数据。 客户端状态更改为 ESTABLELISHED
     6. 服务器收到后， 同时更改状态变为 ESTABLELISHED
     
12. TCP 为什么是 三次握手 而不是两次或者 4次：
     1. RFC 793 指出 三次握手的主要原因是避免历史连接： 其指的是由于网络阻塞问题， 新发送的 SYN 包
        慢与过去的 SYN 包， 此时客户端可以根据返回的确认号来判断此是否是旧的 SYN 报文，若是则第三次
        握手发送 RST 标志位请求中断此 TCP 连接
     2. 同步双发的序列号， 客户端发送报文到服务器端， 服务器端对序列号+1， 因此服务器端发送报文给客户端
        也同样需要收到 客户端的应答报文， 从同步序列号。
     3. 避免资源浪费： 发生 SYN 阻塞时，客户端迟迟没收到 ACK 又会发生 SYN， 服务器端不知道自己的 ACK
                     送入带客户端没有， 因此每收到 SYN 都会建立一个新的连接。
   注： 「四次握手」：三次握手就已经理论上最少可靠连接建，所以不需要使⽤更多的通信次数。    
     
13. ISN 如何产生
      a. 根据 RFC1948 :  M + F(localhot, localpost, remotehost, remoteport)
         M 是时钟： 每4ms + 1
         F 是哈希函数， 通过端口号+主机隐射一个值

12 TCP 数据分层不放在 IP 层是因为什么

     a. IP 层没有超时重传机制， 因此 TCP 放在 IP 层分发，接受方对数据进行检验缺少某个片区则不会返回
        ACK 标志， 此时客户端 TCP 超时则会重传整个数据。 
    

13 TCP 四次挥手：
     a.  客服端发生 FIN 报文 即将 FIN标志位置1，发送完后客户端状态更改为 FIN_WAIT_1
     b.  服务器端接收到后，发送应答报文将 ACK 值置位1 ，此时状态更好为 CLOSED_WAIT
     c.  客户端接收到后， 将状态更改为 FIN_WAIT_2
     d.  服务器端接受完数据后，发送 FIN 报文， 状态更该为 LST_ACK
     e.  客户端接受后，发送 ACK 报文， 并且状态更改为 TIME_WAITE
     f.  服务器端接收到 ACK 报文，进入到 closed 状态 此时服务器端关闭连接
     g.  客户端等待 2MSL 之后断开连接。

14. 为什么需要等待 2个 MSL 时间： 防止客户端没有接收到 ACK 重发 FIN
a. MSL 是 Maximum Segment Lifetime，报⽂最⼤⽣存时间，它是任何报⽂在⽹络上存在的最⻓时间，超过这个时
间报⽂将被丢弃。因为 TCP 报⽂基于是 IP 协议的，⽽ IP 头中有⼀个 TTL 字段，是 IP 数据报可以经过的最⼤路
由数，每经过⼀个处理他的路由器此值就减 1，当此值为 0 则数据报将被丢弃，同时发送 ICMP 报⽂通知源主机。

b. 2MSL 的时间是从客户端接收到 FIN 后发送 ACK 开始计时的。如果在 TIME-WAIT 时间内，因为客户端的 ACK
 没有传输到服务端，客户端接收到了服务端发的 FIN 报文，那么 2MSL 时间将重新计时。

流量控制： 
    1. TCP 连接的每一方都要通告自己的接收窗口 （rwnd），当一方需要处理速度跟不上发送端发送速度，降低
       自己的窗口大小并通知发送方，当窗口减小为0， 应用层需要首先清空缓冲区数据。
       
慢启动、拥塞预防、快速重发和快速恢复
```

### UDP

``` 
数据报： 完整，独立的数据实体，携带着从源节点到目的节点的足够信息， 对这些节点间之前的数据交换和传输网络没有任何依赖。一般将不可靠协议传送的数据称为数据报。

UDP应用：DNS（Domain Name System，域名系统）。DNS 负责把对人类友好的主机名转换成 IP 地址。

UDP又称为无协议服务：
         1. 不保证交付顺序：不设置包序号，不重排，不会发生队首阻塞。
         2. 不跟踪程序状态：不必建立连接或重启状态机
         3. 不保证信息交付：不确认，不重传，无超时。
         4. 没有拥塞控制：不内置客户端或网络反馈机制。
         
UDP 数据报文格式：
         1.  源端口号 16位    目的端口号 16 位
         2.   包长度 16 位    校验和 16 位
                         数据

UDP 应用场景
     1.  DNS
     2. 视频、 音频等多媒体重复
     3. 广播通信
```

### TLS

```
TLS： Transport Layer Security， 位于会话层主要为应用层提供： 数据加密， 数据完整性检验， 身份验证。

数据加密： 混淆数据的机制。
身份验证： 验证身份标识有效性的机制。
完整性： 检测信息是否被篡改和伪造。
```

### HTTP 

```
HTTP： 超文本传输协议(HyberText Transfer Protocol) 是互联网最普遍采用的应用协议。

HTTP0.9： 
    1. 客户端/服务器  请求/响应
    2. ACSII协议， 运行于TCP/IP协议之上
    3. 设计用来传输超文本文档
    4. 服务器和客户端在每次的连接在请求以后都会断开

telnet google.com 80
Connect to 74.125.xxx.xxx

请求： GET/ about/
响应： (超文本文档)

请求只有一行，包括 GET 方法和要请求的文档的路径。响应是一个超文本文档，没
有首部，也没有其他元数据，只有 HTML。

HTTP1.0：
    1. 请求行加入HTTP 版本号， 请求行后可跟多行首部
    2. [响应对象]前面增加响应状态行
    3. [响应状态行]后[响应对象]前可跟多行首部
    4. 响应对象不局限于对象文本： 图片， 文件
    5. 服务器与客户端之间的连接在每次请求之后都会关闭。
    
总结： 1. 请求和响应首部都使用 ASCII 编码，但响应对象本身可以是任何类型：HTML 文
         件、纯文本文件、图片，或其他内容类型。
      2. 事实上，HTTP 中的“HTT”（Hypertext Transfer，超文本传输）在协议出现后不久就已经用词不当了。在
         实践中，HTTP 迅速发展为超媒体传输协议，但最初的名字则沿用至今。
         $> telnet website.org 80
            Connected to xxx.xxx.xxx.xxx
            GET /rfc/rfc1945.txt HTTP/1.0 ➊   请求行
            User-Agent: CERN-LineMode/2.15 libwww/2.17b3
            Accept: */*
            
            HTTP/1.0 200 OK ➋   响应状态行
            Content-Type: text/plain
            Content-Length: 137582
            Expires: Thu, 01 Dec 1997 16:00:00 GMT
            Last-Modified: Wed, 1 May 1996 12:45:26 GMT
            Server: Apache 0.84
           （纯文本响应）  响应对象
           （连接关闭）
           
HTTP1.1: 持久连接、分块编码传输、 字节范围请求、 增强的缓存机制、 传输编码/请求管道  (HTTP权威指南)

          1. 持久化连接， 引入 Connection 字段， 设置 Connection: keep-alive, 则传输
             不会在请求之后关闭，而是继续保持连接。 设置 Connection: closed 连接在请求完成
             后断开
          2. 字节范围请求： 响应对象发送之前， 会先发送字节数。
          3. 请求管道： 持久化连接使得同时会出现多个 HTTP 请求， 他们必须满足 FIFO 队列
                      请求管道使得这个队列移动到服务器端， 使得服务器端可以并行处理请求，但是
                      HTTP1.x 只支持按找 FIFO 队列顺序进出， 不允许先渲染完者直接返回。
                      
           telnet website.org 80
            Connected to xxx.xxx.xxx.xxx
            GET /index.html HTTP/1.1 ➊   
            Host: website.org
            User-Agent: Mozilla/5.0 (Macintosh; Intel Mac OS X 10_7_4)... (snip)
            Accept: text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8
            Accept-Encoding: gzip,deflate,sdch
            Accept-Language: en-US,en;q=0.8
            Accept-Charset: ISO-8859-1,utf-8;q=0.7,*;q=0.3
            Cookie: __qca=P0-800083390... (snip)       cookie字段 
            
            HTTP/1.1 200 OK ➋
            Server: nginx/1.0.11
            Connection: keep-alive
            Content-Type: text/html; charset=utf-8
            Via: HTTP/1.1 GWA
            Date: Wed, 25 Jul 2012 20:23:35 GMT
            Expires: Wed, 25 Jul 2012 20:23:35 GMT
            Cache-Control: max-age=0, no-cache       新的缓存字段
            Transfer-Encoding: chunked
            
            100 ➌                范围请求
            <!doctype html>
            (snip)
            100
            (snip)
            0 ➍
            
            GET /favicon.ico HTTP/1.1 ➎   相同TCP连接下， 新的数据请求
            Host: www.website.org
            User-Agent: Mozilla/5.0 (Macintosh; Intel Mac OS X 10_7_4)... (snip)
            Accept: */*
            Referer: http://website.org/
            Connection: close ➏           连接关闭
            Accept-Encoding: gzip,deflate,sdch
            Accept-Language: en-US,en;q=0.8
            Accept-Charset: ISO-8859-1,utf-8;q=0.7,*;q=0.3
            Cookie: __qca=P0-800083390... (snip)
            
            HTTP/1.1 200 OK ➐
            Server: nginx/1.0.11
            Content-Type: image/x-icon
            Content-Length: 3638
            Connection: close
            Last-Modified: Thu, 19 Jul 2012 17:51:44 GMT
            Cache-Control: max-age=315360000
            Accept-Ranges: bytes
            Via: HTTP/1.1 GWA
            Date: Sat, 21 Jul 2012 21:35:22 GMT
            Expires: Thu, 31 Dec 2037 23:55:55 GMT
            Etag: W/PSA-GAu26oXbD
            
            （图标数据）
            （关闭连接）
          
总结： HTTP1.0 已经将 HTTP 协议的模板基本确定下来， HTTP1.1引入了更多的首部字段增添完善的功能：
      HTTP 1.1 协议添加了内容、编码、字符集，甚至语言的协商机制，还添加了传输编码、缓存指令、客户端    
      cookie 等十几个可以每次请求都协商的字段。

背景： 用户和 Web 开发者都迫切想要通过 HTTP 1.1 达到一种几近[实时]的响应速度和协议性能

HTTP2.0: 改变传输性能 实现低延迟高吞吐量 
  1. HTTP2.0 设计目标：
       a. 相对使用 TCP 的 HTTP1.1, 用户在大多数情况下的感知延迟要有实质上的可度量改进。
       b. 解决 HTTP1.1 队首阻塞问题
       c. 并行操作无需与服务器建立多个连接， 改进 TCP 的利用率
       d. 保持 HTTP1.1 语义， 包括 HTTP 方法， 状态码， URI， 以及首部字段
       e. 明确 HTTP1.1 与 HTTP2.0 可以相互操作， 特别是在中间介质层上。
  
  2. HTTP2.0 增强的核心是： 二进制分帧层
     a. HTTP1.X 信息是 headr+body 纯文本的方式， 换行符作为分隔符
     b. HTTP2.0 信息被分割为更小单元校[消息]和[帧]，它们采用二进制格式编码，其中消息就是一系列的帧。
     
  3. HTTP2.0 引入的新的概念：所有通信都在一个 TCP 连接中进行
      a. 流： 已经建立的双向字节流，每个流都有唯一的标识符。 在一个连接上可以承担任意数量的流, 流序号
             是奇数，是由客户端发起的。
      b. 消息： 逻辑上的 HTTP 消息：请求或者响应， 其包含一系列帧
      c. 帧：最小的信息单元， 最少包括帧首部和当前流序号，可能是首部、主体
      
  4. 交错并行发送帧：
       a. HTTP2.0 采用二进制分帧层， 将 HTTP 消息用帧表示， 发送过程中可以打乱顺序，在另一端重新组合。
       因此响应之间互不干扰， 交错并行发送。
       b. 采用这种方式： 通过一个 TCP 连接便可以并行处理请求和响应， 消除不必要的延迟。
       c. 流具有优先级， 0 最高， 2^31-1 最低。 总结： 不能一味的规定按优先级发送，可能引入
          队首阻塞，因此允许对不同优先级的流进行交错发送， 但是也应该在可能的情况下最大限度保证
          高优先级的流优先发送。
 5. 服务器推送： 
       a. 服务器可以不需要客户端对该资源的请求而向客户端推送其会用到的资源，减少客户端额外的请求。
          到那时服务器推送的几点限制：
                 I. 必须遵循请求-响应循环，服务器必须在客户端请求后发出推送请求。
                 II. 推送资源之前， 服务器在返回的响应帧中 PUSH_PROMISE 提示客户端要发送
                     其他资源， 客户端允许后再完成其后的推送， 推送的资源直接进入客户端缓存。
 6. 首部压缩：
       a. 客户端 和 服务端 都使用首部表， [跟踪] 和 [存储] 之前发送的键-值对, 
       b. 客户端和服务器端拥有一份共同的首部表， 当第二次请求时只需要发送差异信息
          新的字段会自动添加到表中， 若是原有字段会进行更新。
     
```

[首部字段](https://datatracker.ietf.org/doc/html/draft-ietf-httpbis-header-compression)

### HTTPS

```
引入 TLS 会话层， 解决 HTTP 三个缺点  
1. 混淆数据、  身份验证、  数据完整性

RSA 协商密匙算法 ：  缺点是缺少前向保密， 一旦服务器私匙泄露，TSL报文的信息都可以一览无遗。
2. TLS 握手
   a. TCP 三次握手建立连接后， 客户端发送一个随机数c、自己的 TLS 版本号 和 密码套件列表
      这个随机数会被服务器保留， 其是生成对称密匙的材料之一   【client hello】
   b. 服务器确认支持的 TLS 协议版本号， 从客户端可接受的 [加密套件列表]? 中选择一个，同时发生一个随
      机数。 【server hello】
      密码套件： 密匙交换算法+签名算法+对称加密算法+摘要算法   WITH 进行分割前面是密匙交换算法+签名算法
      名称，后是对称算法+摘要算法的名称 e.g:Cipher Suite: TLS_RSA_WITH_AES_128_GCM_SHA256”。
      密匙交换算法 和 签名算法：RSA  对称算法： AES， 长度是128位 摘要算法是 SHA256
   c. 服务器发送自己证书 【Server Certificate】
   d. 服务器发送 【server hello down】 服务器消息发送完毕
     证书包含的信息：
           I. 公匙
           II.持有者信息
          III.证书认证机构 CA
           IV. CA 对这份证书的数字签名和使用算法
           V. 有效期
      客户端得到证书后首先会逐级验证书，之后会利用 HASH 算法对证书内容进行 HASH 计算， 同时利用公匙对签名进行计算二者值相同信任该证书。
   e. 客户端生成一个随机数(pre-master), 用服务器的RSA公匙加密后发送给服务器端  【client key exchange】
   d. 服务器用RSA私匙解密出客户端发过来的随机数， 此时一共有三个随机数：client Random、 server Random、 pre-master 双方用这三个随机数生成对称密匙，用于后续的请求/响应加密
   e. 客户端此时发送消息： change Cipher spec ，告知服务器端用对称密匙进行加密传输
   f. 客户端再发一个 Finished 消息， 将之前所发数据做个摘要，再用会话密匙进行加密，传给服务器
      让其做验证
   g. 服务器同样发送 change Cipher spec 和 Encrypted Handshake Message 消息，双方都验证
      加密和解密没有问题，握手正式完成
      
ECDHE 算法： 服务器目前常用的密匙协商算法
      基础： 离散对数 -->   a^i mod p = b   
            b 称作真数 i 称作对数  ， 知道真数 b 和 a 、p也很难求出对数 i
       DH算法 ： 双方先确认底数G 和 模数 p 这是公开的, 然后各自生成私匙 s1, s2 作为各自的对数
                计算出各自的真数作为公匙A、B。 交换各自公匙后
                B^s1（mod p）  和   A^s2 (mod p) 结果相同为K， 这个K值是他们之间的对称加密
       DHE算法：DH 算法有两类， 一是static DH算法，私匙只在客户端随机生成， 服务器端不变
               DHE 算法， 客户端和服务器端私匙都是随机生成的
       ECDHE算法： DHE算法计算性能不佳， 因此在此基础上利用椭圆曲线特性使用更少的计算量计算出公匙
```



### URL

```
URI: 统一资源标识符

URL：统一资源定位符 ， 其是 URI 的具体实现， 使用唯一地址来标记资源
  <scheme>://<username>:<password>@<host>:<port>/<path>;<params>?<query>#<frag>

<scheme>： 方案。 告诉浏览器如何去访问资源。 SMTP FTP HTTP 在没有浏览器之前， 用户获取特定的
            资源都需要使用特定的客户端访问资源， 浏览器简化了用户操作， 使用户通过浏览器便可以访问
            到特定的资源。
<params>: 参数。 仅依靠特定路径，我们可能无法满足访问特定资源的需求， 加入 params 进一步定义
          资源， 路径是可以多段的，每段路径后都可以加入 ‘；’后跟参数 key=value
<query>:  查询。 询问在上述路径是否有特定属性的资源。
<frag>: 片段。 资源内部某一个子资源，比如页面上的一张图片。 #<frag> 不会发送给服务器， 只在客户端使用。
```



### WEB 性能优化

```
核心： 
     a.  致力于减少不必要的网络延迟。
     b.  传输的数据压缩至最少。

1.web 性能优化： 性能优化在于弄清楚数据在传输过程中层与层之间的交互和层内的限制。
         (性能优化的很大一部分工作就是把不同层之间的交互过程分解开来，弄清楚每一层次交互的约束和限制.)

            1. 传输过程中的 [延迟] 和 [带宽] 对Web性能的影响
            2. TCP 协议对 HTTP 的传输限制
            3. HTTP 协议本身在具体场景下的限制
            4. Web 应用的发展趋势和性能需求
            5. 浏览器的局限性和优化思路

2. web 性能从文档加载时间到页面加载时间的转变：
    1. 富媒体网页的出现， 简单的文档加载变成了文档加载资源。 
    2. 页面加载时间： Page Load Time， 从视觉上是页面旋转图标旋转停止经历的时间， 从技术上定义是
                   window.onload事件被触发时的时间 ， 该事件被触发后代表 文档及依赖资源：JavaScript
                   图片、 CSS等下载完毕。
3. Web 应用把网页的简单依赖关系（在标签中使用媒体作为基本内容的补充）转换成了复杂的依赖关系：标记定义结构、样式表定义布局，而脚本构建最终的交互式应用，响应用户输入，并在交互期间创建样式表和标记。
         HTML   -- 浏览器解析 -->   DOM
                                          --->  渲染树 --> 布局  --> 绘制
         CSS    --    ？    -->   CSSOM
    javaScript 脚本会阻塞 DOM 树构建
    渲染和 CSSOM 构建又会阻塞 js 脚本运行， 因此优先将 css 文件放在页面上方，使其快速下载完毕。

WebPageTest.org 是一个开源免费的项目，可以测试世界各地网页的性能。测试用的浏览器在虚拟机中运行，可编程，可配置，有各种连接和浏览器设置可选。

4. 一个 HTTP 请求是由各个独立的阶段组成的：  DNS解析， TCP连接， TSL协商， HTTP请求， 下载资源
       
      a. 减少 DNS 查找
      b. 重用 TCP 连接
      c. 减少 HTTP 重定向
      d. 使用 CDN 
      e. 减少不必要的 HTTP 请求
      
  针对 HTTP 的优化：
      a. 客户端缓存资源          HTTP1.X HTTP2.0
      b. 传输压缩过的内容        HTTP1.X HTTP2.0
      c. 消除不必要的请求开销     HTTP2.0 (首部压缩、服务器推送)  HTTP1.X 资源打包， 拼图
      d. 并行处理请求和响应       HTTP2.0
       
  HTTP2.0 优化建议：
      1. 使用单一的 TCP 连接
      2. 减少不必要的资源打包，和图片合并
      3. 使用服务器推送
```

