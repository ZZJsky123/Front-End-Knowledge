### 前言

Steve Souders：

```
Web 开发，那你技术体系的根基就是 Web 和它赖以存在的大量网络协议：TCP、TLS、UDP、HTTP，
等等。这些协议分别有各自的性能特点和优化技巧，为开发高性能应用，你必须理
解为什么网络那么运行。
```

Ilya Grigorik

```
大多数网站性能的瓶颈都是延迟，而不是带宽！

延迟： 分组从信息源发送到目的地所需的时间
   传播延迟：消息从发送端到接收端需要的时间，是信号传播距离和速度的函数。
   传输延迟：把消息中的所有比特转移到链路中需要的时间，是消息长度和链路速率的函数。
   处理延迟：处理分组首部、检查位错误及确定分组目标所需的时间。
   排队延迟：到来的分组排队等待处理的时间。
   
带宽： 逻辑或物理通信路径最大的吞吐量

Ookla 运营的 http://speedtest.net 可以测试客户端到某个 [本地服务器] 的上传和下载速度
```

### TCP

```
1. TCP 报文格式
   a. 源端口号 16位  目的端口号 16 位
   b. 序列号 32 位
   c. 确认应答号： 32 位
   d. 首部长度 4 位  保留标志位：ACK/RST/SYN/FIN(重要的4个) 窗口大小16位
   e. 校验和 16 位 紧急指针 16 位
   f. 选项
   g. 数据
   
  序列号： 建立 TCP连接时， 生成初始的序列号，之后每次发送都会对序列号的数据进行增加
          其作用是用于解决帧的乱序问题。
  确认应答号： 用于指出已经接收到的帧数据， 表明该序号之前的数据都被接收到了 
  
  ACK: 该位为 1 时， 确认应答位必须有效， 除了 SYN 包之外(发起连接)， 其余包都为1
  RST： 该位为 1 时， TCP 发生异常， 此时必须断开 TCP 连接
  SYN:  该位为 1 时， 请求连接， 此时进行序列号初始值设定
  FIN： 该位为 1 时， 后面已经无数据， 希望断开连接。
  
2. 为什么需要 TCP 连接 ？ TCP 工作在哪一层
   TCP 工作在传输层， 其下的网络层 IP协议 不保证数据可靠交付，其只负责将 TCP 层数据包装成
   数据报进行转发， 但不保证是否转发成功， 是否按序转发, 也不保证数据包的完整性。
   因此 TCP 协议需要承担数据的可靠性， 他保证数据 [无损坏]， [无间隔]， [非冗余]， [按序]。
   
3. TCP 通信协议的特点：
     a. 面向连接： 进行 TCP 通信时需要端到端进行 一对一连接
     b. 可靠： 保证数据传输时的无损坏， 按序， 不冗余
     c. 面向字节流： 数据以字节流的形式
     
4. 如何唯一确定一个 TCP ：
        源端口号、 目的端口号 、源 IP 地址、 目的 IP 地址
        
5. 服务器上 TCP 最大可以连接的数量：
        a. 服务器上 目的IP地址 目的端口号不变， 理论上最大连接数量是 客户端的 IP地址个数 * 端口号数
                  IPV4   2^32 * 2^16 = 2^48
        b. TCP 数量未抵达理论数值的原因
                  a. 每个 socket 都是文件， 有文件描述符限制， 需要修改 ulimit 的数量
                  b. 内存限制
                  
6. TCP 和 UDP 的区别
        a.  连接： TCP 是面向连接的且是一对一， UDP 即刻发送可以一对一， 一对多， 多对多
        b.  可靠： TCP 是可靠传输保证数据成功抵达，并且按照顺序， 同时保证抵达数据无损， 
                  UDP 尽最大努力交付， 只负责发送，不保证数据的可靠性。
        c.  首部字段： TCP 的首部字段较多包括： 源端口号，目的端口号，序列号，确认应答号
                     保留位，窗口大小， 校验和，紧急指针。 UDP 只包含源端口号和目的端口
                     号， 包长度， 校验和 共计8个字节。
        d. 传输方式： TCP 是按流传输， 没有边界，但保证数据按照顺序
                    UDP 是一个包一个包传输， 数据之间边界明显， 并且会有乱序的可能
        e. 数据分片： TCP 数据长度大于 MSS 大小，会被分片， 传输过程中若分片丢失
                    只需要重新传入那个片。在传输层分片，在传输层组装。 mss 默认是
                    536 字节。
                    
                    UDP 在 IP 层进行分片， 若数据长度大于 MTU， 进行数据分片
                    不建议 UDP 数据长度大于 MTU， 一旦分片丢失按照可靠性要求需要
                    重新传输整个包而不是分片， 不符合 UDP 最大努力交付。在 IP 层
                    重新组装。 MTU 大小： 1472 字节上下 1500 字节 1K左右
                    
                     
7. TCP 应用：
              a. FTP 文件传输
              b. HTTP / HTTPS
              
8. TCP 为什么有首部长度字段， UDP 没有：
        1. UDP 首部长度固定， 而 TCP 首部长度有可变长的 [选项] 字段
        
9. TCP 为什么没有包长度， UDP 有
        1. TCP 数据长度等于 IP数据长度- IP首部长度 -TCP首部长度
        2. UDP 也可以根据这种方式算出来， 但是可能为了满足长度是 4字节的整数倍。

10. TCP 选项字段主要用于记录一些在通信过程中会经常使用到的值
        e.g:  MSS 大小  新的窗口大小等

11. TCP 建立连接： 
     1.  建立连接之前， 客户端和服务器端都处于 closed 状态
     2.  开始建立， 服务器端首先发生变化， 首先监听某个端口并处于监听状态。
     3.  客户端初始化序列值， 生成 client_isn ,并将其放入序号字段中， 并将
         SYN 标志位：1， 发送给服务器， 此时状态变为 SYN_SEND。
     4.  服务器收到后， 初始化随机序列号server_isn， 并将其填入序列字段， 并将客户端的发送的TCP
         数据中 client_isn + 1 填入到确认序列号中，将 ACK 和 SYN 标志位设置成 1
         返回给客户端。服务器端状态更改为： [SYN_RCVD]
     5. 客户端收到报文后， 需要返回应答报文， 将服务器端的 server_isn + 1填入确认应答字段
        并将 ACK :1, 此时可以携带数据。 客户端状态更改为 ESTABLELISHED
     6. 服务器收到后， 同时更改状态变为 ESTABLELISHED
     
12. TCP 为什么是 三次握手 而不是两次或者 4次：
     1. RFC 793 指出 三次握手的主要原因是避免历史连接： 其指的是由于网络阻塞问题， 新发送的 SYN 包
        慢与过去的 SYN 包， 此时客户端可以根据返回的确认号来判断此是否是旧的 SYN 报文，若是则第三次
        握手发送 RST 标志位请求中断此 TCP 连接
     2. 同步双发的序列号， 客户端发送报文到服务器端， 服务器端对序列号+1， 因此服务器端发送报文给客户端
        也同样需要收到 客户端的应答报文， 从同步序列号。
     3. 避免资源浪费： 发生 SYN 阻塞时，客户端迟迟没收到 ACK 又会发生 SYN， 服务器端不知道自己的 ACK
                     送入带客户端没有， 因此每收到 SYN 都会建立一个新的连接。
   注： 「四次握手」：三次握手就已经理论上最少可靠连接建，所以不需要使⽤更多的通信次数。    
     
13. ISN 如何产生
      a. 根据 RFC1948 :  M + F(localhot, localpost, remotehost, remoteport)
         M 是时钟： 每4ms + 1
         F 是哈希函数， 通过端口号+主机隐射一个值

12 TCP 数据分层不放在 IP 层是因为什么

     a. IP 层没有超时重传机制， 因此 TCP 放在 IP 层分发，接受方对数据进行检验缺少某个片区则不会返回
        ACK 标志， 此时客户端 TCP 超时则会重传整个数据。 
    

13 TCP 四次挥手：
     a.  客服端发生 FIN 报文 即将 FIN标志位置1，发送完后客户端状态更改为 FIN_WAIT_1
     b.  服务器端接收到后，发送应答报文将 ACK 值置位1 ，此时状态更好为 CLOSED_WAIT
     c.  客户端接收到后， 将状态更改为 FIN_WAIT_2
     d.  服务器端接受完数据后，发送 FIN 报文， 状态更该为 LST_ACK
     e.  客户端接受后，发送 ACK 报文， 并且状态更改为 TIME_WAITE
     f.  服务器端接收到 ACK 报文，进入到 closed 状态 此时服务器端关闭连接
     g.  客户端等待 2MSL 之后断开连接。

14. 为什么需要等待 2个 MSL 时间： 防止客户端没有接收到 ACK 重发 FIN

    a. MSL 是 Maximum Segment Lifetime，报文最大生存时间，它是任何报在网络上存在的最大时间，超过这个
       时间报将被丢弃。因为 TCP 报⽂基于是 IP 协议的，IP 头中有个 TTL 字段，是 IP 数据报可以经过的最          大路由数，每经过个处理他的路由器此值就减 1，当此值为 0 则数据报将被丢弃，同时发送 ICMP 报通知源主
       机。 MSL 时间 > TTL 消耗为0的时间

    b. 2MSL 的时间是从客户端接收到 FIN 后发送 ACK 开始计时的。如果在 TIME_WAIT 时间内，因为客户端的 
       ACK没有传输到服务端，客户端又接收到了服务端发的 FIN 报文，那么 2MSL 时间将重新计时。
       2MSL 是等待可能新的FIN报文的时间。
       
       
15 全连接队列 和 半连接队列

   a. Liux 内核中维护两个队列： SYN 队列 和 accepted 队列
   
   b. 客户端发起 SYN 连接报文， 服务器端接收到后返回 SYN+ACK 此时客户端
      还没有回应， Linux将连接放入到半连接队列中。
      
   c. 客户端进行第三次握手后， 连接建立， Linux 会将连接从半连接队列中移除， 并建立新的
      完全连接，将其放入到完全连接队列中 accepted。
      
16. TCP 三次握手性能优化

   a. 客户端优化
      I. 三次握手的一个主要目的是同步序列号， 当客户端发送 SYN 报文后， 会等待服务器端发送
         SYN + ACK 报文， 若在规定时间内未有接收到，则客户端会进行重复， 重发的次数存在
         tcp_syn_retries 中， 默认是5次。 第一次是 1s 后， 第二次是 2s 后， 第三次是
         4s 秒后， 第4次是 8秒 后， 第5次是 16秒 后， 第5次之后， 客户端又会继续等待32s
         若没有等到则终止第三次连接。因此根据 [网络稳定]、[服务器繁忙程度] 减少重传次数。
         
   b. 服务器端优化
   
17. 如何绕过三次握手：  使用 TCP FAST OPEN 减少握手带来的 1 个 RTT消耗
    
    a. 首次发起 SYN 报文中包含 Fast Open 选项， 该选项对应的 cookie 为空， 服务器接收后
       知道客户端请求 Fast Open Cookie 
    b. 支持 TCP Fast Open 的服务器会生成 cookie,将其放入到选项字段中，随后将 SYN+ACK
       报文回传至客户端
    c. 客户端接收到回传报文后， 将 cookie 缓存至本地
    
    e. 之后再次发起请求， SYN 请求连接报文可以携带数据， 并将本地缓存的 cookie 放在选项字段
       中一并发给服务器
    f. 服务器收到后会对 cookie 进行检验， 如果 cookie 有效则将数据送入相应的应用程序中，并在
       返回的 SYN+ACK 报文中对数据接受进行确认， 若 cookie 无效则只会返回基本的 SYN+ACK 报文
    g. 客户端接收后， 发送 ACK 报文进行确认， 若数据没有被确认则会同时携带数据再次回传给服务器。
    
 TCP Fast Open ： 握手的同时发送数据， cookie 会存储在 TCP 的 Options 字段中。服务器根据
                  选线字段是否有 cookie 来判断是否是 TFO。 因为普通的 TCP 连接 cookie
                  应该储存在 HTTP 报文的 cookie 字段。
                  
18. 四次挥手优化： 
      客户端优化
          a. FIN_WAIT1优化： 客户端发送 FIN 报文太长时间没有回应则会重新发送 FIN 报文
             重传次数由 tcp_orphan_retries 决定。默认是 8 次， 当传输次数超过 设置的
             数值连接会直接关闭掉。 若恶意攻击， 数据缓存区有数据 FIN 报文会一直发布出去
             或者攻击方下载大文件，会使自己的接收窗口为0， 报文发不出去， 此时需要调整
             tcp_max_orphans 数量，当孤儿连接数量超过此值， 新的孤儿连接会被直接通过
             RST 报文强制关闭。
          b. FIN_WAIT2优化： 当客户端接收到 ACK 应答后成为 FIN_WAIT2 状态，若是
             使用 shutdown 关闭连接可以等待， 若是使用 close 关闭此时已经不能读和写
             因此过一段时间会自动关闭， 等待时间由：tcp_fin_timeout 参数控制。默认时间
             是 60 秒。
          c. Time_Wait： 其作用是两个 1. 防止历史数据  2. 确认收到服务器重新回传的 FIN 报文
                 TIME_WAIT 过短之前发送的历史数据由于网络阻塞问题暂时滞留在服务器， 连接关闭后
                 端口重用建立新的连接，此时历史数据到达可能会被接收造成数据混乱问题。
                II. 客户端最后发送的 ACK 报文会网络阻塞了， 此时若客户端直接断开， 则建立新连接
                  时服务器端一直处于 LOCK_WAIT 状态回返回给客户端 RST 报文强制关闭连接。
                III. 当并发的孤儿连接增多， 相应的 TIME_WAITE 也会增多， 其默认数量由 
                     tcp_max_tw_buckets 决定，超过其数量新的关闭连接就没有 TIME_WAITE
                     这容易有数据错乱， 因此应该适当增大该采纳数数量。
       服务器端优化：
       
      
      注： TCP 是全双工协议， 有可能双方同时发送 FIN 报文，这种状态是被允许的，此时双方都认为
           自己是主动方，同时都会有 TIME_WAITE 的状态。
    

流量控制： 
    1. TCP 连接的每一方都要通告自己的接收窗口 （rwnd），当一方需要处理速度跟不上发送端发送速度，降低
       自己的窗口大小并通知发送方，当窗口减小为0， 应用层需要首先清空缓冲区数据。
       
慢启动、拥塞预防、快速重发和快速恢复
```

### UDP

``` 
数据报： 完整，独立的数据实体，携带着从源节点到目的节点的足够信息， 对这些节点间之前的数据交换和传输网络没有任何依赖。一般将不可靠协议传送的数据称为数据报。

UDP应用：DNS（Domain Name System，域名系统）。DNS 负责把对人类友好的主机名转换成 IP 地址。

UDP又称为无协议服务：
         1. 不保证交付顺序：不设置包序号，不重排，不会发生队首阻塞。
         2. 不跟踪程序状态：不必建立连接或重启状态机
         3. 不保证信息交付：不确认，不重传，无超时。
         4. 没有拥塞控制：不内置客户端或网络反馈机制。
         
UDP 数据报文格式：
         1.  源端口号 16位    目的端口号 16 位
         2.   包长度 16 位    校验和 16 位
                         数据

UDP 应用场景
     1.  DNS
     2. 视频、 音频等多媒体重复
     3. 广播通信
```

### TLS

```
TLS： Transport Layer Security， 位于会话层主要为应用层提供： 数据加密， 数据完整性检验， 身份验证。

数据加密： 混淆数据的机制。
身份验证： 验证身份标识有效性的机制。
完整性： 检测信息是否被篡改和伪造。
```

### HTTP 

```
HTTP： 超文本传输协议(HyberText Transfer Protocol) 是互联网最普遍采用的应用协议。

幂等方法： GET:   向服务器请求数据
         HEAD ： 向服务器请求数据的首部字段
         PUT ： 客户端向服务器写入文档， 服务器利用 URL 对文档进行命名
         DELETE ： 请求服务器删除特定 URL 文档
         OPTIONS： 请求服务器告知其所支持的方法，该字段用于与服务器进行协商。
         
非幂等方法： Post 

幂等： 多次请求结果相同。

不安全的方法： PUT DELETE 恶意软件会使用这些方法擅自删除服务器的文件。

HTTP0.9：                    协议只有一行
    1. 客户端/服务器  请求/响应
    2. ACSII协议， 运行于TCP/IP协议之上
    3. 设计用来传输超文本文档
    4. 服务器和客户端在每次的连接在请求以后都会断开

telnet google.com 80
Connect to 74.125.xxx.xxx

请求： GET/ about/
响应： (超文本文档)

请求只有一行，包括 GET 方法和要请求的文档的路径。响应是一个超文本文档，没
有首部，也没有其他元数据，只有 HTML。

HTTP1.0：  加入首部字段
    1. 请求行加入HTTP 版本号， 请求行后可跟多行首部
    2. [响应对象]前面增加响应状态行
    3. [响应状态行]后[响应对象]前可跟多行首部
    4. 响应对象不局限于对象文本： 图片， 文件
    5. 服务器与客户端之间的连接在每次请求之后都会关闭。
    
总结： 1. 请求和响应首部都使用 ASCII 编码，但响应对象本身可以是任何类型：HTML 文
         件、纯文本文件、图片，或其他内容类型。
      2. 事实上，HTTP 中的“HTT”（Hypertext Transfer，超文本传输）在协议出现后不久就已经用词不当了。在
         实践中，HTTP 迅速发展为超媒体传输协议，但最初的名字则沿用至今。
         $> telnet website.org 80
            Connected to xxx.xxx.xxx.xxx
            GET /rfc/rfc1945.txt HTTP/1.0 ➊   请求行
            User-Agent: CERN-LineMode/2.15 libwww/2.17b3
            Accept: */*
            
            HTTP/1.0 200 OK ➋   响应状态行
            Content-Type: text/plain
            Content-Length: 137582
            Expires: Thu, 01 Dec 1997 16:00:00 GMT
            Last-Modified: Wed, 1 May 1996 12:45:26 GMT
            Server: Apache 0.84
           （纯文本响应）  响应对象
           （连接关闭）
           
HTTP1.1: 持久连接、分块编码传输、 增强的缓存机制、 传输编码/请求管道  (HTTP权威指南)

          1. 持久化连接， 引入 Connection 字段， 设置 Connection: keep-alive, 则传输
             不会在请求之后关闭，而是继续保持连接。 设置 Connection: closed 连接在请求完成
             后必须断开。
             
          2. 请求管道： 持久化连接让一个 请求-响应 完成后可以发送第二个 请求-响应，管道化是指
                      第一个请求送出后， 客户端不需要等到响应回来，可以直接发送下一个请求。 即
                      多条请求放如队列中，按顺序发送，但是 HTTP1.x 规定服务器只支持按照 FIFO 
                      队列顺序进行响应返回， 不允许先渲染完者直接返回。 请求管道容易引入队首阻塞
                      同时请求管道必须处理一方突然关闭时链接恢复，特别是非幂等请求：POST
                      
          3. 分块编码传输： 在响应首部字段规定 transfer-encoding: chunked 则响应主体则会
                         分块传输， 每一个块之前会标明长度， 直到长度为0表示块传输结束。
                         该属性适应于： 响应主体长度未知时， 避免服务器先缓存资源计算长度再进行传输
                                     使得 TTFB (Time TO First Byte) 有可能过长。采用分块编码
                                     服务器实时传输，同时可以告知浏览器什么时候结束。
                                     
          4. content-length: 响应主体的长度。 在持久化连接中， 返回响应主体长度使得客户端可以知道什么
                             时候响应完成， 若未规定响应长度客户端将会一直处于等待状态。
                             
          5. content-Encoding: 响应主体的编码方式，此时字段用于规定响应主体用什么方式进行压缩传输。
          
          6. 多个 TCP 连接请求， 一个页面可能需要多个资源， 如果只有一个 TCP 连接， 则页面只能一个
             资源一个资源加载，页面渲染速度慢， 因此通过建立多个 TCP 通道对多项资源进行同时申请。
                      
           telnet website.org 80
            Connected to xxx.xxx.xxx.xxx
            GET /index.html HTTP/1.1 ➊   
            Host: website.org
            User-Agent: Mozilla/5.0 (Macintosh; Intel Mac OS X 10_7_4)... (snip)
            Accept: text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8
            Accept-Encoding: gzip,deflate,sdch
            Accept-Language: en-US,en;q=0.8
            Accept-Charset: ISO-8859-1,utf-8;q=0.7,*;q=0.3
            Cookie: __qca=P0-800083390... (snip)       cookie字段 
            
            HTTP/1.1 200 OK ➋
            Server: nginx/1.0.11
            Connection: keep-alive
            Content-Type: text/html; charset=utf-8
            Via: HTTP/1.1 GWA
            Date: Wed, 25 Jul 2012 20:23:35 GMT
            Expires: Wed, 25 Jul 2012 20:23:35 GMT
            Cache-Control: max-age=0, no-cache       新的缓存字段
            Transfer-Encoding: chunked
            
            100 ➌                范围请求
            <!doctype html>
            (snip)
            100
            (snip)
            0 ➍
            
            GET /favicon.ico HTTP/1.1 ➎   相同TCP连接下， 新的数据请求
            Host: www.website.org
            User-Agent: Mozilla/5.0 (Macintosh; Intel Mac OS X 10_7_4)... (snip)
            Accept: */*
            Referer: http://website.org/
            Connection: close ➏           连接关闭
            Accept-Encoding: gzip,deflate,sdch
            Accept-Language: en-US,en;q=0.8
            Accept-Charset: ISO-8859-1,utf-8;q=0.7,*;q=0.3
            Cookie: __qca=P0-800083390... (snip)
            
            HTTP/1.1 200 OK ➐
            Server: nginx/1.0.11
            Content-Type: image/x-icon
            Content-Length: 3638
            Connection: close
            Last-Modified: Thu, 19 Jul 2012 17:51:44 GMT
            Cache-Control: max-age=315360000
            Accept-Ranges: bytes
            Via: HTTP/1.1 GWA
            Date: Sat, 21 Jul 2012 21:35:22 GMT
            Expires: Thu, 31 Dec 2037 23:55:55 GMT
            Etag: W/PSA-GAu26oXbD
            
            （图标数据）
            （关闭连接）
          
总结： HTTP1.0 已经将 HTTP 协议的模板基本确定下来， HTTP1.1引入了更多的首部字段增添完善的功能：
      HTTP 1.1 协议添加了内容、编码、字符集，甚至语言的协商机制，还添加了传输编码、缓存指令、客户端    
      cookie 等十几个可以每次请求都协商的字段。

背景： 用户和 Web 开发者都迫切想要通过 HTTP 1.1 达到一种几近[实时]的响应速度和协议性能

HTTP2.0: 改变传输性能 实现低延迟高吞吐量 
  1. HTTP2.0 设计目标：
       a. 相对使用 TCP 的 HTTP1.1, 用户在大多数情况下的感知延迟要有实质上的可度量改进。
       b. 解决 HTTP1.1 队首阻塞问题
       c. 并行操作无需与服务器建立多个连接， 改进 TCP 的利用率
       d. 保持 HTTP1.1 语义， 包括 HTTP 方法， 状态码， URI， 以及首部字段
       e. 明确 HTTP1.1 与 HTTP2.0 可以相互操作， 特别是在中间介质层上。
  
  2. HTTP2.0 增强的核心是： 二进制分帧
     a. HTTP1.X 信息是 headr+body 纯文本的方式， 换行符作为分隔符
     b. HTTP2.0 信息被分割为更小单元[消息]和[帧]，它们采用二进制格式编码，其中消息就是一系列的帧。
     
  3. HTTP2.0 引入的新的概念：所有通信都在一个 TCP 连接中进行
      a. 流： 已经建立的双向字节流，每个流都有唯一的标识符。 
             在一个连接上可以承担任意数量的流, 流序号是奇数，是由客户端发起的。
             一个响应-请求为一个流， 流中的报文以二进制帧的形式发送。
             
      b. 消息： 逻辑上的 HTTP 消息：请求或者响应， 其包含一系列帧
      
      c. 帧：最小的信息单元， 最少包括帧首部和当前流序号，可能是首部、主体
      
  4. 交错并行发送帧： 解决 HTTP 队首阻塞， 建立多个 TCP 连接问题
       a. HTTP2.0 采用二进制分帧， 将 HTTP 消息用帧表示， 发送过程中可以打乱顺序，在另一端重新组合。
       因此响应之间互不干扰， 交错并行发送。
       b. 采用这种方式： 通过一个 TCP 连接便可以并行处理请求和响应， 消除不必要的延迟。
       c. 流具有优先级， 0 最高， 2^31-1 最低。 总结： 不能一味的规定按优先级发送，可能引入
          队首阻塞，因此允许对不同优先级的流进行交错发送， 但是也应该在可能的情况下最大限度保证
          高优先级的流优先发送。
 
 HTTP 2.0 引入流的概念， 一个连接上有多个流，流就是 HTTP1.X 中的一组请求-响应， 流中的报文被分为
 多个帧， 以二进制帧的形式进行传输。 多个流之间的帧采用并行交错的形式进行传输， 因此可以替代 HTTP 1.X
 中的为达到并行请求资源而建立多个 TCP 连接。客户端交错并行传输请求帧解决多个 TCP 连接问题。 服务器端交错
 并发执行帧解决队首阻塞问题。
          
 5. 服务器推送： 
       a. 服务器可以不需要客户端对该资源的请求而向客户端推送其会用到的资源，减少客户端额外的请求。
          到那时服务器推送的几点限制：
                 I. 必须遵循请求-响应循环，服务器必须在客户端请求后发出推送请求。
                 II. 推送资源之前， 服务器在返回的响应帧中 PUSH_PROMISE帧 提示客户端要发送
                     其他资源， 客户端允许后再完成其后的推送， 推送的资源直接进入客户端缓存。
                     
 6. 首部压缩：
       a. 客户端 和 服务端 都使用首部表， [跟踪] 和 [存储] 之前发送的键-值对, 
       b. 客户端和服务器端拥有一份共同的首部表， 当第二次请求时只需要发送差异信息
          新的字段会自动添加到表中， 若是原有字段会进行更新。
     
```

[首部字段](https://datatracker.ietf.org/doc/html/draft-ietf-httpbis-header-compression)

### HTTPS

```
引入 TLS 会话层， 解决 HTTP 三个缺点  
1. 混淆数据、  身份验证、  数据完整性

RSA 协商密匙算法 ：  缺点是缺少前向保密， 一旦服务器私匙泄露，TLS 报文的信息都可以一览无遗。
2. TLS 握手
   a. TCP 三次握手建立连接后， 客户端发送一个随机数c、自己的 TLS 版本号 和 密码套件列表
      这个随机数会被服务器保留， 其是生成对称密匙的材料之一   【client hello】
   b. 服务器确认支持的 TLS 协议版本号， 从客户端可接受的 [加密套件列表]? 中选择一个，同时发生一个随
      机数。 【server hello】
      密码套件： 密匙交换算法+签名算法+对称加密算法+摘要算法   WITH 进行分割前面是密匙交换算法+签名算法
      名称，后是对称算法+摘要算法的名称 e.g:Cipher Suite: TLS_RSA_WITH_AES_128_GCM_SHA256”。
      密匙交换算法 和 签名算法：RSA  对称算法： AES， 长度是128位 摘要算法是 SHA256
   c. 服务器发送自己证书 【Server Certificate】
   d. 服务器发送 【server hello down】 服务器消息发送完毕
     证书包含的信息：
           I. 公匙
           II.持有者信息
          III.证书认证机构 CA
           IV. CA 对这份证书的数字签名和使用算法
           V. 有效期
      客户端得到证书后首先会逐级验证书，之后会利用 HASH 算法对证书内容进行 HASH 计算， 同时利用公匙对签名进行解密 (数字签名是利用私匙加密的) 二者值相同信任该证书。
   e. 客户端生成一个随机数(pre-master), 用服务器的RSA公匙加密后发送给服务器端  【client key exchange】
   d. 服务器用RSA私匙解密出客户端发过来的随机数， 此时一共有三个随机数：client Random、 server Random、 pre-master 双方用这三个随机数生成对称密匙，用于后续的请求/响应加密
   e. 客户端此时发送消息： change Cipher spec ，告知服务器端用对称密匙进行加密传输
   f. 客户端再发一个 Finished 消息， 将之前所发数据做个摘要，再用会话密匙进行加密，传给服务器
      让其做验证
   g. 服务器同样发送 change Cipher spec 和 Encrypted Handshake Message 消息，双方都验证
      加密和解密没有问题，握手正式完成
 RSA 算法缺陷： 不支持前向保密， pre-master 是利用公匙加密利用私匙解密一旦私匙泄露则数据将会被完全
              暴露出来。
     
              
    
ECDHE 算法： 服务器目前常用的密匙协商算法
      基础： 离散对数 -->   a^i mod p = b   
            b 称作真数 i 称作对数  ， 知道真数 b 和 a 、p也很难求出对数 i
       DH算法 ： 双方先确认底数G 和 模数 p 这是公开的, 然后各自生成私匙 s1, s2 作为各自的对数
                计算出各自的真数作为公匙A、B。 交换各自公匙后
                B^s1（mod p）  和   A^s2 (mod p) 结果相同为K， 这个K值是他们之间的对称加密
       DHE算法：DH 算法有两类， 一是static DH算法，私匙只在客户端随机生成， 服务器端不变
               DHE 算法， 客户端和服务器端私匙都是随机生成的
       ECDHE算法： DHE算法计算性能不佳， 因此在此基础上利用椭圆曲线特性使用更少的计算量计算出公匙
       
  注： 使用 HTTPS 会多增加 2 个 RTT往返时间。
  
  HTTPS 的优化：
      a. 产生性能损耗的两个方面
         I. TLS 协议握手：
            a. 使用 ECDHE 算法客户端和服务器端都要临时生成椭圆曲线公私匙
            b. 使用 RSA 算法生成 pre-master
            c. 客户端验证证书时会访问 CA 获取 CRL 或者 OCSP， 目的是验证服务器端证书是否被吊销。
         
         II. 对称加密算法： 生成会话密匙
             目前主流算法： ASE / CHCHA20 性能可以并且 cpu 厂商还会对硬件进行优化
             
      b. 硬件优化：
            HTTPS 因为涉及到密匙计算，属于 [计算密集型]，对 CPU 要求较高， 可支持 AES-NI 指令集
            的 CPU 可以用于支持 AES 算法优化。
            
     c. 软件优化
          I. 软件升级
          
          II 协议优化： 密匙协商过程优化
             (1). TLS 使用 RSA 需要4次握手，且不具备前向安全， 因此替换成 ECDHE 算法，该算法
                  可以在第三次握手时，第四次握手前发送加密的应用数据从而可以将原先的 2个 RTT 减少
                  为 1个RTT。
             (2). ECDHE 使用椭圆曲线，建议使用 x25519 曲线。
          III. 协议升级：
               TLS1.2 --->  TLS1.3/ 1.4
               (2). TLS1.3 原先的4次握手 改成了 2 次 1个RTT 就完成了
               (3). 密匙交换算法只支持 ECDHE 算法， 废除了 RSA 和 DH 算法
               (4). 仅支持 5 种密码套件
               
     d. 证书优化：
              I. 证书传输： 内容越少越好
                 同等安全条件下， 椭圆曲线证书比RSA证书密匙长度更短
                 
              II. 证书访问优化：
                  证书验证是逐级验证，验证过程中需要计算证书完整性，有时需要访问 CA 查看证书是否被
                  吊销。
               CRL： Certifiate Revocation List 由 CA 维护的证书吊销列表定时更新
                 问题1： 实时性差，定时更新而不是实时更新
                 问题2： 下载表后还需要遍历用时长
               OCSP: Online Certifiate Status Protocl 在线证书状态
                 使用 OCSP 向 CA 询问，CA会返回该协议状态。为了解决网络状态和CA 服务器忙碌
                 使用 OCSP Stapling 服务器周期性询问 CA 并缓存，同时由于签名的存在服务器无法
                 对其进行修改。
                 
     e. 会话复用
             
```



### URL

```
URI: 统一资源标识符

URL：统一资源定位符 ， 其是 URI 的具体实现， 使用唯一地址来标记资源
  <scheme>://<username>:<password>@<host>:<port>/<path>;<params>?<query>#<frag>

<scheme>： 方案。 告诉浏览器如何去访问资源。 SMTP FTP HTTP 在没有浏览器之前， 用户获取特定的
            资源都需要使用特定的客户端访问资源， 浏览器简化了用户操作， 使用户通过浏览器便可以访问
            到特定的资源。
<params>: 参数。 仅依靠特定路径，我们可能无法满足访问特定资源的需求， 加入 params 进一步定义
          资源， 路径是可以多段的，每段路径后都可以加入 ‘；’后跟参数 key=value
<query>:  查询。 询问在上述路径是否有特定属性的资源。
<frag>: 片段。 资源内部某一个子资源，比如页面上的一张图片。 #<frag> 不会发送给服务器， 只在客户端使用。
```



### WEB 性能优化

```
核心： 
     a.  致力于减少不必要的网络延迟。
     b.  传输的数据压缩至最少。

1.web 性能优化： 性能优化在于弄清楚数据在传输过程中层与层之间的交互和层内的限制。
         (性能优化的很大一部分工作就是把不同层之间的交互过程分解开来，弄清楚每一层次交互的约束和限制.)

            1. 传输过程中的 [延迟] 和 [带宽] 对Web性能的影响
            2. TCP 协议对 HTTP 的传输限制
            3. HTTP 协议本身在具体场景下的限制
            4. Web 应用的发展趋势和性能需求
            5. 浏览器的局限性和优化思路

2. web 性能从文档加载时间到页面加载时间的转变：
    1. 富媒体网页的出现， 简单的文档加载变成了文档加载资源。 
    2. 页面加载时间： Page Load Time， 从视觉上是页面旋转图标旋转停止经历的时间， 从技术上定义是
                   window.onload事件被触发时的时间 ， 该事件被触发后代表 文档及依赖资源：JavaScript
                   图片、 CSS等下载完毕。
3. Web 应用把网页的简单依赖关系（在标签中使用媒体作为基本内容的补充）转换成了复杂的依赖关系：标记定义结构、样式表定义布局，而脚本构建最终的交互式应用，响应用户输入，并在交互期间创建样式表和标记。
         HTML   -- 浏览器解析 -->   DOM
                                          --->  渲染树 --> 布局  --> 绘制
         CSS    --    ？    -->   CSSOM
    javaScript 脚本会阻塞 DOM 树构建
    渲染和 CSSOM 构建又会阻塞 js 脚本运行， 因此优先将 css 文件放在页面上方，使其快速下载完毕。

WebPageTest.org 是一个开源免费的项目，可以测试世界各地网页的性能。测试用的浏览器在虚拟机中运行，可编程，可配置，有各种连接和浏览器设置可选。

TTFB： Time To First Byte ， 第一个字节抵达浏览器。

4. 一个 HTTP 请求是由各个独立的阶段组成的：  DNS解析， TCP连接， TSL协商， HTTP请求， 下载资源
       
      a. 减少 DNS 查找
      b. 重用 TCP 连接
      c. 减少 HTTP 重定向
      d. 使用 CDN 
      e. 减少不必要的 HTTP 请求
      
  针对 HTTP 的优化：
      a. 客户端缓存资源          HTTP1.X HTTP2.0
      b. 传输压缩过的内容        HTTP1.X HTTP2.0
      c. 消除不必要的请求开销     HTTP2.0 (首部压缩、服务器推送)  HTTP1.X 资源打包， 拼图
      d. 并行处理请求和响应       HTTP2.0
       
  HTTP2.0 优化建议：
      1. 使用单一的 TCP 连接
      2. 减少不必要的资源打包，和图片合并
      3. 使用服务器推送
```

